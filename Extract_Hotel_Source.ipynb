{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "rolled-butler",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from pandas import DataFrame\n",
    "from requests_html import HTMLSession\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from time import sleep\n",
    "\n",
    "def load_page(url: str, wait_time: int, batches: int, chromedriver_path: str,\n",
    "              opts: Options) -> list:\n",
    "    '''\n",
    "    The browser sometimes return different htmls, fortunately there is a\n",
    "    small variation in patterns. As a workaround, this function tries to reload\n",
    "    the page every time a pattern different from the reference\n",
    "    html is returned.\n",
    "\n",
    "    Parameters:\n",
    "    -----------------------\n",
    "    url :: str\n",
    "        the url of the parent page\n",
    "\n",
    "    wait_time :: int\n",
    "        The pause time before the next scroll down is executed,\n",
    "        allows the browser to load twelve more hotel cards\n",
    "\n",
    "    batches :: int\n",
    "        The number of batches loaded (12 per batch), each scroll\n",
    "        adds 1 batch of hotel cards\n",
    "\n",
    "    Returns:\n",
    "    -----------------------\n",
    "    hotel_cardsBS :: list of BeautifulSoup Object\n",
    "        list containing immediate parent of the hotel cards and its children\n",
    "\n",
    "    '''\n",
    "    # launch driver load get initial page html, ...\n",
    "    # ... and check if the same as reference html\n",
    "\n",
    "    driver = webdriver.Chrome(chromedriver_path, options=opts)\n",
    "    driver.maximize_window()\n",
    "    driver.get(url)\n",
    "    selector = 'body .resp-section .inner-section .resp-row .resp-col .main-inner section .h-listing .listings'\n",
    "\n",
    "    page_init = driver.page_source\n",
    "    soup_init = BeautifulSoup(page_init, 'html.parser')\n",
    "    cardsBS4_init = soup_init.select_one(selector)\n",
    "\n",
    "    if cardsBS4_init is None:\n",
    "        # look at driver.navigate().refresh(), it might be better\n",
    "        # cardsBS4_init is only none when the html loaded is different from ...\n",
    "        # ... the referrence html, reload.\n",
    "        driver.quit()\n",
    "        load_page(url, wait_time, batches, chromedriver_path, opts)\n",
    "    else:\n",
    "        i = 1\n",
    "        while i < batches:\n",
    "            # this adds 12 more hotel cards per iteration, if i > 84, ...\n",
    "            # the script stops, that is we end up with 1008 (hopefully- net ...\n",
    "            # problems) hotel cards\n",
    "\n",
    "            script = 'window.scrollTo(0, document.body.scrollHeight,)'\n",
    "            # scroll down to the bottom\n",
    "            driver.execute_script(script)\n",
    "\n",
    "            # gives time for the second scrolldown, ...\n",
    "            # ... adjust according to net speed.\n",
    "            sleep(wait_time)\n",
    "            i += 1\n",
    "\n",
    "        print('load_page done')\n",
    "        # the resulting html after scroll downs\n",
    "        page = driver.page_source\n",
    "        soup = BeautifulSoup(page, 'html.parser')\n",
    "        hotel_cards_container = soup.select_one(selector)\n",
    "\n",
    "        hotel_cards = hotel_cards_container.find_all('li', recursive=False)\n",
    "\n",
    "        return hotel_cards # return list\n",
    "\n",
    "\n",
    "def request(url: str, init_query: str, requests: HTMLSession) -> BeautifulSoup:\n",
    "    '''\n",
    "    Follows the same logic as the selenium page loader, but for vanilla soup\n",
    "    objects. Reload page if the html of the page is different than that of the\n",
    "    reference page. Keep reloading until html of query is equivalent to\n",
    "    reference html.\n",
    "\n",
    "    Parameter:\n",
    "    ----------------------------------------------------------------------------\n",
    "    url :: str\n",
    "        the url of the parent page\n",
    "\n",
    "    init_query :: str , this is the initial css selector to be used for\n",
    "                  checking\n",
    "        initial query with attribute names from reference html\n",
    "\n",
    "    Return:\n",
    "    ----------------------------------------------------------------------------\n",
    "    soup_init :: bs4Object\n",
    "        the parent page html, this is similar to the reference html\n",
    "\n",
    "    Note:\n",
    "    ----------------------------------------------------------------------------\n",
    "        requests.get(url) randomly returns different html formats, fortunately\n",
    "        the set of html formats returned is finite. Reload the page until the\n",
    "        reference format is returned.\n",
    "    '''\n",
    "    page = requests.get(url)\n",
    "    \n",
    "    soup_init = BeautifulSoup(page.content, 'html.parser')\n",
    "\n",
    "    # use this query uses attribute names similar to reference html, ...\n",
    "    # ... it this is None, the html loaded is different\n",
    "    check_query = soup_init.select_one(init_query)\n",
    "\n",
    "    if check_query is None:\n",
    "        # reload the html\n",
    "        request(url, init_query, requests)\n",
    "    else:\n",
    "        # once init_query loads the expected attributes, return the soup\n",
    "        return soup_init\n",
    "   \n",
    "\n",
    "def init_df() -> DataFrame:\n",
    "    # features must be defined in the same order as the definitions ...\n",
    "    # ... in Hotel class\n",
    "    features = ['hotel_name', 'price', 'rating', 'loc', 'city',\n",
    "                'province', 'landmarks', 'terminals',\n",
    "                'rooms', 'ameneties', 'reviews']\n",
    "\n",
    "    hotel_dataFrame = pd.DataFrame(columns=features)\n",
    "    return hotel_dataFrame\n",
    "\n",
    "\n",
    "def url_req() -> str:\n",
    "    url = ('https://ph.hotels.com/search.do?resolved-location=COUNTRY%3A10'\n",
    "           + '233139%3AUNKNOWN%3AUNKNOWN&destination-id=10233139&q-destina'\n",
    "           + 'tion=Philippines&q-check-in=2021-10-10&q-check-out=2021-10-1'\n",
    "           + '1&q-rooms=1&q-room-0-adults=2&q-room-0-children=0')\n",
    "\n",
    "    return url\n",
    "\n",
    "\n",
    "def add_hotels(cards: list, df: DataFrame):\n",
    "    '''\n",
    "    Add the attributes of one hotel to the hotel dataFrame\n",
    "    '''\n",
    "    for card in cards:\n",
    "        Hotel(card, df)\n",
    "\n",
    "\n",
    "def save_hotels(df: DataFrame):\n",
    "    file = 'data/Hotel.csv'\n",
    "    df.to_csv(file)\n",
    "\n",
    "\n",
    "def extract_data():\n",
    "    chromedriver_path = os.getcwd() + '\\\\chromedriver\\\\chromedriver.exe'\n",
    "    opts = Options()\n",
    "    opts.add_argument(' â€” headless')\n",
    "\n",
    "    # initialize dataframe\n",
    "    hotels = init_df()\n",
    "\n",
    "    # returns of BeautifulSoup hotel cards\n",
    "    hotel_cards = load_page(url=url_req(), wait_time=10,\n",
    "                            batches=1,\n",
    "                            chromedriver_path=chromedriver_path,\n",
    "                            opts=opts\n",
    "                            )\n",
    "    add_hotels(hotel_cards, hotels)      # add hotels\n",
    "    save_hotels(hotels)                  # save hotels dataFrame to csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "adapted-jumping",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Hotel:\n",
    "    def __init__(self, hotel_card: BeautifulSoup, dataFrame: DataFrame):\n",
    "        '''\n",
    "        Initialize a hotel, where card is a bs4 Object,\n",
    "        containing the hotel data\n",
    "\n",
    "        note to self: classes can access global definitions, no need init class\n",
    "        with requests object for indivPage\n",
    "        and reviewPage\n",
    "        '''\n",
    "\n",
    "        # helper variables\n",
    "        self.card = hotel_card\n",
    "        self.address = self.get_address()\n",
    "\n",
    "        individualPage = self.get_hotelPageSoup()\n",
    "        reviewPage = self.get_reviewPageSoup(individualPage)\n",
    "\n",
    "        # the features\n",
    "        self.hotel_name = self.get_name()\n",
    "        self.price = self.get_price()\n",
    "        self.rating = self.get_rating()\n",
    "        self.loc = self.address[0]\n",
    "        self.city = self.address[-4]\n",
    "        self.province = self.address[-2]\n",
    "        self.landmarks = self.get_landmarks(individualPage)\n",
    "        self.terminals = self.get_terminals(individualPage)\n",
    "        self.rooms = self.get_rooms(individualPage)\n",
    "        self.ameneties = self.get_amenities()\n",
    "        self.reviews = self.get_reviews(reviewPage)\n",
    "\n",
    "        # add to DataFrame\n",
    "        self.add_hotel(dataFrame)\n",
    "\n",
    "    def get_name(self) -> str:\n",
    "        '''\n",
    "        Returns:\n",
    "            hotel_name :: str\n",
    "        '''\n",
    "        hotel_name = self.card['data-title']\n",
    "        return hotel_name\n",
    "\n",
    "    def get_price(self) -> int:\n",
    "        '''\n",
    "        Returns\n",
    "            price :: int\n",
    "\n",
    "        pricing(Php) for 2 adults, one night sta y.\n",
    "        '''\n",
    "        # returns the likes of 'P6,221'\n",
    "        price = self.card.find('a', class_='price-link').get_text()\n",
    "        # filter returns list of all chars in price ['P',',','6','7','8'], ...\n",
    "        # ... loop over each element and\n",
    "\n",
    "        # create a new list satisfying only i.isdigit, join this into a ...\n",
    "        # ... string convert string into int\n",
    "\n",
    "        price_int = int(''.join(i for i in filter(None, price) if i.isdigit()))\n",
    "\n",
    "        return price_int\n",
    "\n",
    "    def get_rating(self) -> float:\n",
    "        '''\n",
    "        Returns\n",
    "            rating :: float\n",
    "        '''\n",
    "        rating = (self.card.find('strong',\n",
    "                                 class_='guest-reviews-badge').get_text())\n",
    "\n",
    "        # float(the digit chars and '.' in the list of chars of rating)\n",
    "        rating_float = float(''.join(i for i in filter(None, rating) if\n",
    "                                     (i.isdigit() | (i == '.'))))\n",
    "\n",
    "        # filter() :: str -> [char]\n",
    "        return rating_float\n",
    "\n",
    "    def get_address(self) -> list:\n",
    "        '''\n",
    "        Returns\n",
    "            address :: str\n",
    "\n",
    "        full address of the hotel, via list with format\n",
    "        [loc1, loc2, city, zipCode, province, country]\n",
    "        '''\n",
    "\n",
    "        address_ = self.card.find('span', class_='address').get_text()\n",
    "        address = address_.split(', ')                     # to get the list\n",
    "\n",
    "        # city has index -4 when from right to left, this is a list of locs ...\n",
    "        # ... from city -> country\n",
    "        address_cp = address[-4:]\n",
    "\n",
    "        # concatenate the specific addresses\n",
    "        address_sp = self.join_specificAdds(address[:-4])\n",
    "        # address now has elements: [address_sp, city, zipCode, province, ...\n",
    "        # ... country]\n",
    "        address_cp.insert(0, address_sp)\n",
    "        return address_cp\n",
    "\n",
    "    def get_landmarks(self, individualPage: BeautifulSoup) -> list:\n",
    "        '''\n",
    "        Returns the list of all landmarks\n",
    "        with format:\n",
    "            landmark - distance\n",
    "        '''\n",
    "        selector = ('body div.resp-section main.inner-section '\n",
    "                    + 'div#property-details '\n",
    "                    + 'div#flexible-container-bottom '\n",
    "                    + 'div.whats-around-content-landmarks-transport')\n",
    "\n",
    "        landmarks = individualPage.select_one(selector)\n",
    "\n",
    "        landmarks = landmarks.find(class_='whats-around-content landmarks')\n",
    "\n",
    "        landmarks_col = [landmark.get_text() for landmark in\n",
    "                         landmarks.select('div.landmarks-expandable-wrapper '\n",
    "                                          + 'ul.landmark-list li')]\n",
    "\n",
    "        return landmarks_col\n",
    "\n",
    "    def get_terminals(self, individualPage: BeautifulSoup) -> dict:\n",
    "        '''\n",
    "        get dictionary of terminals where\n",
    "        dict.key = transportation type\n",
    "        dict.value = [Name of Terminal - distance from hotel]\n",
    "        '''\n",
    "\n",
    "        # cut the full query, into two parts ...\n",
    "        selector = ('body div.resp-section main.inner-section '\n",
    "                    + 'div#property-details '\n",
    "                    + 'div#flexible-container-bottom '\n",
    "                    + 'div.whats-around-content-landmarks-transport')\n",
    "\n",
    "        transpo_soup = individualPage.select_one(selector)\n",
    "        transports = transpo_soup.find(class_='whats-around-content transport')\n",
    "\n",
    "        # categegory['class'] returns a list, regardless the first entry ...\n",
    "        # ... is the actual category of transportation\n",
    "        transport_cat = [category['class'][0] for category in\n",
    "                         transports.select('ul')]\n",
    "\n",
    "        # ... airport, train-station, etc\n",
    "\n",
    "        # helper function,  returns the list of all terminals with category cat\n",
    "        def terminal_query(cat): return ([station.get_text() for station in\n",
    "                                          transports.select('ul.{0} li'\n",
    "                                                            .format(cat))])\n",
    "\n",
    "        transports_col = {category: terminal_query(category) for category in\n",
    "                          transport_cat}\n",
    "        return transports_col\n",
    "\n",
    "    def get_rooms(self, individualPage: BeautifulSoup) -> int:\n",
    "        '''\n",
    "        Returns the number of rooms in the hotel\n",
    "        '''\n",
    "\n",
    "        # query was two long for one line, divided in to two parts\n",
    "        hotelSize_query = ('#at-a-glance div.cont-wrap '\n",
    "                           + 'div.fact-sheet-columns div.col-8-24 '\n",
    "                           + 'div.info-box ul li')\n",
    "\n",
    "        # there are two instances of ul li tags in html, select_one ...\n",
    "        # always select first instance which is the one we need\n",
    "        hotel_size = individualPage.select_one(hotelSize_query).get_text()\n",
    "        # concatenated strings for shorter query in line\n",
    "\n",
    "        room_count = [int(word) for word in hotel_size.split()\n",
    "                      if word.isdigit()][0]\n",
    "\n",
    "        # the extraction method follows from\n",
    "        # hotel_size has initial value 'This hotel has N number of rooms'\n",
    "        # .split() splits according to the presence of each word\n",
    "        # the list comprehension checks all strings with digits, ...\n",
    "        # ... in our case the room count, this is the same for all cases\n",
    "        # need to add exceptions, to avoid errors\n",
    "\n",
    "        return room_count\n",
    "\n",
    "    def get_amenities(self) -> list:\n",
    "        '''\n",
    "        list of all amenities available to hotel\n",
    "        '''\n",
    "        amenities = self.card.select_one('.hmvt8258-amenities')\n",
    "        amenities_col = [amenity.get_text() for amenity in\n",
    "                         amenities.select('li')]\n",
    "\n",
    "        return amenities_col\n",
    "\n",
    "    def get_reviews(self, review_page: BeautifulSoup) -> list:\n",
    "        '''\n",
    "        Returns a list of the reviews for the hotel\n",
    "        Each review is a dictionary and has the following items:\n",
    "\n",
    "         'reviewer': name of reviewer\n",
    "         'rating': rating given be reviewer\n",
    "         'trip type': type of the trip; how long did the reviewer stay\n",
    "         'comment': what the reviewer had to say in particular\n",
    "        '''\n",
    "\n",
    "        # helper variables and functions\n",
    "\n",
    "        # helper functions\n",
    "        def get_content(card, class_name):\n",
    "            return card.find(class_=class_name).get_text()\n",
    "\n",
    "        def to_float(content):  # converts strings to float\n",
    "            return float(''.join(i for i in\n",
    "                                 filter(None, content)\n",
    "                                 if (i.isdigit() | (i == '.'))))\n",
    "\n",
    "        # get the attribute as per class name assigned\n",
    "        def review(card): return {'reviewer': get_content(card,\n",
    "                                                          class_names[0]),\n",
    "                                  'rating': to_float(get_content(card,\n",
    "                                                                 class_names[1])\n",
    "                                                     ),\n",
    "                                  'trip type': get_content(card,\n",
    "                                                           class_names[2]),\n",
    "                                  'comment': get_content(card,\n",
    "                                                         class_names[3])\n",
    "                                  }\n",
    "\n",
    "        # Names of the classes that point to an ...\n",
    "        # ... attribute of a review card\n",
    "        class_names = ['reviewer', 'rating-score', 'trip-type-nights',\n",
    "                       'expandable-content description']\n",
    "\n",
    "        review_cards = review_page.select('div.review-card')\n",
    "\n",
    "        # get formatted card reviews for 15 reviews\n",
    "        reviews = [review(card) for card in review_cards[0:15]]\n",
    "        return reviews\n",
    "\n",
    "    def add_hotel(self, dataFrame):\n",
    "        '''\n",
    "        Adds the hotel to a dataFrame\n",
    "\n",
    "        Parameters\n",
    "        -----------------------------\n",
    "        dataFrame :: Pandas.DataFrame\n",
    "        '''\n",
    "        hotel = self.__dict__\n",
    "\n",
    "        # remove unnecessary features\n",
    "        hotel.pop('card')\n",
    "        hotel.pop('address')\n",
    "\n",
    "        dataFrame.append(hotel, ignore_index=True)\n",
    "\n",
    "    # helper functions\n",
    "    def get_hotelPageSoup(self) -> BeautifulSoup:\n",
    "        '''\n",
    "        Gets the individual hotel card\n",
    "        '''\n",
    "\n",
    "        # get the text in the attribute href\n",
    "        href = self.card.find('a', class_='property-name-link')['href']\n",
    "        # this is the link to the individual hotel information\n",
    "        href_url = 'https://ph.hotels.com' + href\n",
    "        # problem with 'link' + 'link' + 'link' notation, changed back to current format\n",
    "        init_query = 'body div.resp-section main.inner-section div#property-details div#flexible-container-bottom div.whats-around-content-landmarks-transport'\n",
    "        requests = HTMLSession()\n",
    "        \n",
    "        soup_href = request(href_url, init_query, requests)\n",
    "        return soup_href\n",
    "\n",
    "    def get_reviewPageSoup(self, idPage: BeautifulSoup) -> BeautifulSoup:\n",
    "        '''\n",
    "        Gets the review page from the indivdual card\n",
    "        '''\n",
    "\n",
    "        revPage_linkQuery = idPage.select_one('div#property-reviews '\n",
    "                                              + 'div.see-all-reviews a')\n",
    "        \n",
    "        reviewPage_link = 'https://ph.hotels.com' + revPage_linkQuery['href']\n",
    "        init_query = 'div.review-card'\n",
    "        requests = HTMLSession()\n",
    "        review_page = request(reviewPage_link, init_query, requests)\n",
    "\n",
    "        return review_page\n",
    "\n",
    "    def join_specificAdds(self, specific_address: str) -> str:\n",
    "        '''\n",
    "        there are instances where there are 3 separate specific address before\n",
    "        city hence the need specific_address is a list of the addresses before\n",
    "        the city\n",
    "        '''\n",
    "        specific_add = ''\n",
    "        index = 1\n",
    "        for i in specific_address:\n",
    "            if index != len(specific_address):\n",
    "                # add the first address and  ', ' to separate from next address\n",
    "                specific_add += (i + ', ')\n",
    "                index += 1\n",
    "            else:\n",
    "                # add the last specific address\n",
    "                specific_add += i\n",
    "                return specific_add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reserved-improvement",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load_page done\n"
     ]
    }
   ],
   "source": [
    "extract_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "existing-brunswick",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if data is loaded currectly\n",
    "fp = 'data/Hotel.csv'\n",
    "data = pd.read_csv(fp)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "treated-thesaurus",
   "metadata": {
    "tags": []
   },
   "source": [
    "<h3> <b> Test case for querying on single hotel card </b> </h3>\n",
    "<i> Used as basis for the code above </i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "individual-refund",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we have 26 distinct hotels\n"
     ]
    }
   ],
   "source": [
    "hotel_cards = hotel_cardsBS.find_all('li', recursive=False) # creates one BS obj per card from hotel card BeautifulSoup\n",
    "print('we have {0} distinct hotels'.format(len(hotel_cards)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "serial-january",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "<h3> <b> Inspecting one of the hotel cards </b> </h3>\n",
    "Upon inspection the ff were idd.\n",
    "<li> an a tag with further data given by the attribute href\n",
    "<li> address: in _2oHhXM contains address with format: specific, town/city, zip, province, Philippines \n",
    "<li> amenities: in ?\n",
    "<li> price: in ? #rate is one day for 2 persons\n",
    "<li> h ref has it all, must go to href for number of rooms\n",
    "<blockquote>\n",
    "    <li> number of rooms in:\n",
    "    <li> customer reviews in:\n",
    "    <li> add landmarks, and getting around: in \n",
    "</blockquote>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "optimum-definition",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# try getting information from 1 hotel card\n",
    "# proof of concept\n",
    "hotel_sample = hotel_cards[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "virtual-developer",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Conrad Manila'"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hotel_name = hotel_sample['data-title']\n",
    "hotel_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "adapted-latex",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "rating = hotel_sample.find('strong',class_='guest-reviews-badge').get_text()\n",
    "rating_decimal = float(''.join(i for i in filter(None,rating) if (i.isdigit()|(i=='.'))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "greater-moderator",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Pool', 'Free parking', 'Airport transfer', 'Spa', 'Gym', 'Restaurant']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amenities     = hotel_sample.select('.hmvt8258-amenities')\n",
    "amenities_col = [amenity.get_text() for amenity in amenities[0].select('li')]\n",
    "amenities_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "contained-context",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "address = hotel_sample.find('span', class_='address').get_text()\n",
    "address       # can be split; address.split(', ') returns a list of loc, loc, mmo .... regardless start from last entry\n",
    "              # ie get the index of Philippines and go back this gives us | address.split(', ')[-1], pa front pero pa back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "smart-outline",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6561"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "price = hotel_sample.find('a', class_='price-link').get_text()          # returns the likes of 'P6,221' \n",
    "price_int = int(''.join(i for i in filter(None,price) if i.isdigit()))  # filter returns list of all chars in price ['P',',','6','7','8'], loop over each element and \n",
    "                                                                        # create a new list satisfying only i.isdigit, join this into a string convert string into int\n",
    "price_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "included-statistics",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "href     = hotel_sample.find('a', class_='property-name-link')['href']\n",
    "href_url = 'https://ph.hotels.com'+ href                                             # this is the link to the individual hotel information\n",
    "\n",
    "# open the page and get the ff\n",
    "# number of roms\n",
    "# customer review\n",
    "# landmarks\n",
    "\n",
    "requests = HTMLSession()\n",
    "\n",
    "page_href = requests.get(href_url) # requests also returns different htmls sometime, do the same recursion used in selenium loading \n",
    "soup_href = BeautifulSoup(page_href.content, 'html.parser')\n",
    "\n",
    "landMarks_q1 = 'body div.resp-section main.inner-section div#property-details '\n",
    "landMarks_q2 = 'div#flexible-container-bottom div.whats-around-content-landmarks-transport' \n",
    "landmarks_transport = soup_href.select_one(landMarks_q1 + landMarks_q2)                        # gets to long if both queries are in one line\n",
    "\n",
    "landmarks = landmarks_transport.find(class_='whats-around-content landmarks')\n",
    "landmarks_col = [landmark.get_text() for landmark in landmarks.select('div.landmarks-expandable-wrapper ul.landmark-list li')]\n",
    "\n",
    "transports = landmarks_transport.find(class_='whats-around-content transport')\n",
    "transport_categories = [category['class'][0] for category in transports.select('ul')]                 # categegory['class'] returns a list, iregardless the first entry is the actual category\n",
    "\n",
    "transpo = lambda cat: [station.get_text() for station in transports.select('ul.{0} li'.format(cat))]  # helper function gets the list of all transports under category cat, cat :: str\n",
    "transports_col = {cat:transpo(cat) for cat in transport_categories}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "checked-going",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['In Barangay 76',\n",
       " 'SM Mall of Asia - 8 min walk',\n",
       " 'SMX Convention Center - 3 min walk',\n",
       " 'Mall of Asia Arena - 6 min walk',\n",
       " 'World Trade Center Manila - 33 min walk',\n",
       " 'Cultural Center of the Philippines - 44 min walk',\n",
       " \"Children's Museum (Museo Pambata) - 4.2 mi / 6.7 km\",\n",
       " 'Rizal Park - 4.4 mi / 7.1 km']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "landmarks_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "complimentary-shannon",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'airport': ['Ninoy Aquino Intl. Airport (MNL) - 20 min drive '],\n",
       " 'train-station': ['Manila Buenidia Station - 6 min drive ',\n",
       "  'Manila Vito Cruz Station - 7 min drive ',\n",
       "  'Manila Paco Station - 7 min drive '],\n",
       " 'shuttle': ['Airport shuttle (surcharge)']}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transports_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "divided-thanks",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "hSize_q1 = '#at-a-glance div.cont-wrap '          \n",
    "hSize_q2 = 'div.fact-sheet-columns div.col-8-24 div.info-box ul li'   # there are two instances of ul li tags in html, select_one always select first instance which is the one we need in our case\n",
    "hotel_size = soup_href.select_one(hSize_q1 + hSize_q2).get_text()     # this is a bs4 object containing which has a child containing num of rooms\n",
    "                                                                      # concatenated strings for shorter query in line\n",
    "    \n",
    "\n",
    "room_count    = [int(roomCount) for roomCount in hotel_size.split() if roomCount.isdigit()][0]\n",
    "room_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "stunning-savannah",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# open another page for the reviews\n",
    "# starting from the individual hotel card\n",
    "see_allRevs = soup_href.select_one('div#property-reviews div.see-all-reviews a')\n",
    "allRevs_url = 'https://ph.hotels.com' + see_allRevs['href']       # to review\n",
    "\n",
    "\n",
    "reviews_page = requests.get(allRevs_url)\n",
    "reviews_soup = BeautifulSoup(reviews_page.content, 'html.parser')\n",
    "\n",
    "review_cards = reviews_soup.select('div.review-card')\n",
    "\n",
    "# needs another recursion function see first implementation; addresses problem when browser loads different html, keep reloading\n",
    "# until the right html -- review_cards is not NoneType is loaded.\n",
    "\n",
    "review_cards\n",
    "# get only 15\n",
    "\n",
    "# sample query for one card\n",
    "# get the name, rating, trip type and the review , delete this later\n",
    "name = review_cards[0].find(class_='reviewer').get_text()\n",
    "rating = review_cards[0].find(class_='rating-score').get_text()\n",
    "trip_type = review_cards[0].find(class_='trip-type-nights').get_text()\n",
    "comment = review_cards[0].find(class_='expandable-content description').get_text()\n",
    "\n",
    "\n",
    "\n",
    "# implementation\n",
    "# the logic of the ff follows from the logic of the ff query :: name = review_cards[0].find(class_='reviewer').get_text()\n",
    "class_names = ['reviewer', 'rating-score', 'trip-type-nights', 'expandable-content description'] # this are the names of the classes\n",
    "get_content = lambda card, class_name: card.find(class_= class_name).get_text()\n",
    "review      = lambda card: {'reviewer': get_content(card, class_names[0]), \n",
    "                            'rating': get_content(card, class_names[1]),\n",
    "                            'trip type': get_content(card, class_names[2]),\n",
    "                            'comment': get_content(card, class_names[3])\n",
    "                            }\n",
    "\n",
    "reviews = [review(card) for card in review_cards[0:15]]   # get formatted card reviews"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
